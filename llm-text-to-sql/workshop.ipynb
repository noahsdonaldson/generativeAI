{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Natural Language Querying of data in S3 with Athena and Generative AI (Text-to-SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this sample notebook, you'll see how generative AI can simplify the process of querying and analyzing data stored in Amazon S3 using AWS Athena and the Glue Catalog. Instead of manually writing complex SQL queries, we'll showcase how to describe your analysis requirements in plain English text, and leverage a Generative AI model to generate the corresponding Athena SQL queries automatically.\n",
    "\n",
    "Athena is an interactive query service that enables analysts to analyze data in S3 using standard SQL. However, constructing SQL queries, especially for complex analysis requirements, can be challenging. This is where the Glue Catalog can help - it stores table definitions and schemas for your data in S3, allowing Athena to query that data seamlessly.\n",
    "\n",
    "This notebook illustrates how introducing generative AI can bridge the gap. \n",
    "\n",
    "1. Overview of text-to-SQL capabilities using GenAI models\n",
    "2. Utilizing the Glue Catalog table definitions\n",
    "3. Generating and executing Athena SQL queries from natural language descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will need the following to execute the code in this notebook:\n",
    "\n",
    "- Access to Athena (for query execution), S3 (read access), Glue Catalog (For Database and Tables) and Bedrock (LLMs).\n",
    "- Claude 3 Sonnet Model Enabled on Bedrock. You can read more about model access here: https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html\n",
    "- An S3 bucket to store the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "  Downloading awswrangler-3.7.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.101)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (1.34.101)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (1.22.4)\n",
      "Requirement already satisfied: packaging<25.0,>=21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (21.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (15.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging<25.0,>=21.1->awswrangler) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading awswrangler-3.7.3-py3-none-any.whl (378 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.2/378.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: awswrangler\n",
      "Successfully installed awswrangler-3.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install awswrangler pandas boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Preparation\n",
    "\n",
    "Data Preparation and Exploration are crucial aspects of any Generative AI application. For this Text-to-SQL workshop we will begin with loading of sample data files and creating a data catalog as they lay the foundation for effective querying and extracting insights from data using SQL.\n",
    "\n",
    "We will Start by installing required Python libraries AWS SDK for Pandas (awswrangler), Pandas and Boto3. AWS SDK for Pandas (awswrangler) is a Python library that simplifies the interaction between Python and the AWS ecosystem, providing a high-level API for working with a wide range of AWS services, including Amazon S3, Athena, Glue, Redshift, and DynamoDB. The library abstracts the complexity of AWS service integrations, streamlines common data engineering tasks, and integrates with other popular data science and machine learning libraries, making it a valuable tool for developers and data professionals working on AWS-based projects. For more information and references, visit [AWS Wrangler GitHub repository](https://github.com/awslabs/aws-data-wrangler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "We will use a sample ecommerce sales dataset for this sample in the dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Create Database and Tables in Glue Catalog\n",
    "\n",
    "You can learn more about Glue Catalog here: https://docs.aws.amazon.com/prescriptive-guidance/latest/serverless-etl-aws-glue/aws-glue-data-catalog.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use AWS SDK for Pandas (awswrangler) library to interact with Glue Data Catalog and retrieve a list of all databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Database, Description]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# List all databases in the Glue Data Catalog\n",
    "databases = wr.catalog.databases()\n",
    "print(databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below sample code reads the customers.csv file, creates a new database and table in the Glue Data Catalog, writes the data to an S3 location as a Parquet dataset, and then retrieves the first 10 rows of the table using an Athena SQL query.\n",
    "\n",
    "Make sure you replace the \"<BUCKET_NAME>\" with the name of the bucket in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7628/3915012995.py:11: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if \"workshop_test\" not in databases.values:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Database Description\n",
      "0  workshop_test            \n",
      "There are 0 tables in the database workshop_test\n",
      "Creating table customers in the database workshop_test\n",
      "Table customers created in the database workshop_test\n",
      "   Column Name    Type  Partition                 Comment\n",
      "0  customer_id  bigint      False     Unique customer ID.\n",
      "1   first_name  string      False    Customer first name.\n",
      "2    last_name  string      False     Customer last name.\n",
      "3     email_id  string      False      Customer email ID.\n",
      "4    phone_num  string      False  Customer phone number.\n",
      "Records in the table customers\n",
      "   customer_id first_name last_name               email_id     phone_num\n",
      "0            1       John       Doe    johndoe@example.com  123-456-7890\n",
      "1            2       Jane     Smith  janesmith@example.com  123-456-7891\n",
      "2            3        Jim      Bean    jimbean@example.com  123-456-7892\n",
      "3            8     Sophia      Loki    sophial@example.com  123-456-7897\n",
      "4            9      Bruce    Stumps     brucew@example.com  123-456-7898\n",
      "5           10   Scarlett      John  scarlettj@example.com  123-456-7899\n",
      "6            4    Jessica    Rabbit   jessicar@example.com  123-456-7893\n",
      "7            5      Steve   Carrell     stevec@example.com  123-456-7894\n",
      "8            6       Emma      Rock      emmas@example.com  123-456-7895\n",
      "9            7       Ryan      Ryan      ryang@example.com  123-456-7896\n"
     ]
    }
   ],
   "source": [
    "# Create catalog database: workshop_test\n",
    "# Create first table (customers) in the database\n",
    "\n",
    "bucket = \"\"\n",
    "path = f\"s3://{bucket}/data/\"\n",
    "\n",
    "# Read local csv file customers.csv in to a DataFrame\n",
    "df = pd.read_csv(\"dataset/customers.csv\")\n",
    "\n",
    "# Check if the database workshop_test exists\n",
    "if \"workshop_test\" not in databases.values:\n",
    "    wr.catalog.create_database(\"workshop_test\")\n",
    "    print(wr.catalog.databases())\n",
    "else:\n",
    "    print(\"Database workshop_test already exists\")\n",
    "\n",
    "# List all tables in the database workshop_test\n",
    "dbs = wr.catalog.tables(database=\"workshop_test\")\n",
    "# print table count\n",
    "\n",
    "print(\"There are {} tables in the database workshop_test\".format(len(dbs)))\n",
    "\n",
    "\n",
    "print(\"Creating table customers in the database workshop_test\")\n",
    "# Create table customers in the database workshop_test\n",
    "desc = \"Table with list of customers\"\n",
    "param = {\"source\": \"Customer Details Table\", \"class\": \"e-commerce\"}\n",
    "\n",
    "comments = {\n",
    "    \"customer_id\": \"Unique customer ID.\",\n",
    "    \"first_name\": \"Customer first name.\",\n",
    "    \"last_name\": \"Customer last name.\",\n",
    "    \"email_id\": \"Customer email ID.\",\n",
    "    \"phone_num\": \"Customer phone number.\",\n",
    "}\n",
    "\n",
    "res = wr.s3.to_parquet(\n",
    "    df=df,\n",
    "    path=f\"s3://{bucket}/customers/\",\n",
    "    dataset=True,\n",
    "    database=\"workshop_test\",\n",
    "    table=\"customers\",\n",
    "    mode=\"overwrite\",\n",
    "    glue_table_settings=wr.typing.GlueTableSettings(description=desc, parameters=param, columns_comments=comments),\n",
    ")\n",
    "\n",
    "print(\"Table customers created in the database workshop_test\")\n",
    "\n",
    "\n",
    "# Read table customers from the database workshop_test\n",
    "table = wr.catalog.table(database=\"workshop_test\", table=\"customers\")\n",
    "print(table)\n",
    "\n",
    "\n",
    "print(\"Records in the table customers\")\n",
    "\n",
    "# Run a sample query on the table customers\n",
    "df = wr.athena.read_sql_query(\"SELECT * FROM customers LIMIT 10\", database=\"workshop_test\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tables for all the csv files in the dataset folder\n",
      "Table orders created in the database workshop_test\n",
      "Table products created in the database workshop_test\n",
      "Table orderdetails created in the database workshop_test\n",
      "Table payments created in the database workshop_test\n",
      "Table shipments created in the database workshop_test\n",
      "Table reviews created in the database workshop_test\n"
     ]
    }
   ],
   "source": [
    "# Create tables for all the csv files in the dataset folder\n",
    "\n",
    "file_names = [\"orders.csv\", \"products.csv\", \"orderdetails.csv\", \"payments.csv\", \"shipments.csv\", \"reviews.csv\"]\n",
    "\n",
    "comments_dict = {\n",
    "    \"customers\": {\n",
    "        \"customer_id\": \"Unique customer ID.\",\n",
    "        \"first_name\": \"Customer first name.\",\n",
    "        \"last_name\": \"Customer last name.\",\n",
    "        \"email_id\": \"Customer email ID.\",\n",
    "        \"phone_num\": \"Customer phone number.\",\n",
    "    },\n",
    "    \"orderdetails\": {\n",
    "        \"orderdetailid\": \"Unique order detail ID.\",\n",
    "        \"orderid\": \"Unique order ID.\",\n",
    "        \"productid\": \"Unique product ID.\",\n",
    "        \"quantity\": \"Quantity of product ordered.\",\n",
    "        \"price\": \"Price of product.\",\n",
    "    },\n",
    "    \"orders\": {\n",
    "        \"orderid\": \"Unique order ID.\",\n",
    "        \"customerid\": \"Unique customer ID.\",\n",
    "        \"orderdate\": \"Order date.\",\n",
    "        \"totalamount\": \"Total order amount.\",\n",
    "    },\n",
    "    \"payments\": {\n",
    "        \"paymentid\": \"Unique payment ID.\",\n",
    "        \"orderid\": \"Unique order ID.\",\n",
    "        \"paymenttype\": \"Type of payment.\",\n",
    "        \"amount\": \"Payment amount.\",\n",
    "        \"paymentdate\": \"Payment date.\",\n",
    "        \"status\": \"Payment status.\",\n",
    "    },\n",
    "    \"products\": {\n",
    "        \"productid\": \"Unique product ID.\",\n",
    "        \"productname\": \"Product name.\",\n",
    "        \"price\": \"Product price.\",\n",
    "        \"category\": \"Product category.\",\n",
    "        \"stock\": \"Product stock.\",\n",
    "    },\n",
    "    \"reviews\": {\n",
    "        \"reviewid\": \"Unique review ID.\",\n",
    "        \"productid\": \"Unique product ID.\",\n",
    "        \"customerid\": \"Unique customer ID.\",\n",
    "        \"rating\": \"Product rating.\",\n",
    "        \"comment\": \"Review comment.\",\n",
    "        \"reviewdate\": \"Review date.\",\n",
    "    },\n",
    "    \"shipments\": {\n",
    "        \"shipmentid\": \"Unique shipment ID.\",\n",
    "        \"orderid\": \"Unique order ID.\",\n",
    "        \"status\": \"Shipment status.\",\n",
    "        \"estimateddelivery\": \"Estimated delivery date.\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Creating tables for all the csv files in the dataset folder\")\n",
    "\n",
    "for file_name in file_names:\n",
    "    table_name = file_name.split(\".\")[0]\n",
    "    df = pd.read_csv(f\"dataset/{file_name}\")\n",
    "    res = wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=f\"s3://{bucket}/{table_name}/\",\n",
    "        dataset=True,\n",
    "        database=\"workshop_test\",\n",
    "        table=table_name,\n",
    "        mode=\"overwrite\",\n",
    "        glue_table_settings=wr.typing.GlueTableSettings(\n",
    "            description=f\"Table with list of {table_name}.\",\n",
    "            parameters={\"source\": f\"{table_name} Table\", \"class\": \"e-commerce\"},\n",
    "            columns_comments=comments_dict[table_name],\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Table {table_name} created in the database workshop_test\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Check created tables and retrieve schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all tables in the database workshop_test\n",
      "['customers', 'orderdetails', 'orders', 'payments', 'products', 'reviews', 'shipments']\n",
      "Schema for all tables in the database workshop_test\n",
      "{'customers': {'customer_id': 'bigint',\n",
      "               'email_id': 'string',\n",
      "               'first_name': 'string',\n",
      "               'last_name': 'string',\n",
      "               'phone_num': 'string'},\n",
      " 'orderdetails': {'orderdetailid': 'bigint',\n",
      "                  'orderid': 'bigint',\n",
      "                  'price': 'double',\n",
      "                  'productid': 'bigint',\n",
      "                  'quantity': 'bigint'},\n",
      " 'orders': {'customerid': 'bigint',\n",
      "            'orderdate': 'string',\n",
      "            'orderid': 'bigint',\n",
      "            'totalamount': 'double'},\n",
      " 'payments': {'amount': 'double',\n",
      "              'orderid': 'bigint',\n",
      "              'paymentdate': 'string',\n",
      "              'paymentid': 'bigint',\n",
      "              'paymenttype': 'string',\n",
      "              'status': 'string'},\n",
      " 'products': {'category': 'string',\n",
      "              'price': 'double',\n",
      "              'productid': 'bigint',\n",
      "              'productname': 'string',\n",
      "              'stock': 'bigint'},\n",
      " 'reviews': {'comment': 'string',\n",
      "             'customerid': 'bigint',\n",
      "             'productid': 'bigint',\n",
      "             'rating': 'bigint',\n",
      "             'reviewdate': 'string',\n",
      "             'reviewid': 'bigint'},\n",
      " 'shipments': {'estimateddelivery': 'string',\n",
      "               'orderid': 'bigint',\n",
      "               'shipmentid': 'bigint',\n",
      "               'status': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# New Database in the Glue Data Catalog\n",
    "database = \"workshop_test\"\n",
    "\n",
    "# List all tables in the database workshop_test\n",
    "all_tables = wr.catalog.tables(database=database)\n",
    "\n",
    "# Get list of all table names\n",
    "tables = all_tables[\"Table\"].tolist()\n",
    "\n",
    "print(\"List of all tables in the database workshop_test\")\n",
    "print(tables)\n",
    "\n",
    "\n",
    "# Get schema for all tables\n",
    "print(\"Schema for all tables in the database workshop_test\")\n",
    "\n",
    "all_schemas = {}\n",
    "for table in tables:\n",
    "    schema_str = wr.catalog.get_table_types(database=database, table=table)\n",
    "    all_schemas[table] = schema_str\n",
    "\n",
    "pprint.pprint(all_schemas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate data load by fetching top 2 records from each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customers', 'orderdetails', 'orders', 'payments', 'products', 'reviews', 'shipments']\n",
      "First 2 rows of the table customers\n",
      "   customer_id first_name last_name               email_id     phone_num\n",
      "0            1       John       Doe    johndoe@example.com  123-456-7890\n",
      "1            2       Jane     Smith  janesmith@example.com  123-456-7891\n",
      "First 2 rows of the table orderdetails\n",
      "   orderdetailid  orderid  productid  quantity   price\n",
      "0              1        1          1         2   25.99\n",
      "1              2        2          4         1  699.99\n",
      "First 2 rows of the table orders\n",
      "   orderid  customerid   orderdate  totalamount\n",
      "0        1           1  2024-04-01        85.97\n",
      "1        2           2  2024-04-01       699.99\n",
      "First 2 rows of the table payments\n",
      "   paymentid  orderid  paymenttype  amount paymentdate     status\n",
      "0          1        1  Credit Card   85.97  2024-04-01  Completed\n",
      "1          2        2       PayPal  699.99  2024-04-01  Completed\n",
      "First 2 rows of the table products\n",
      "   productid     productname  price     category  stock\n",
      "0          1  Wireless Mouse  25.99  Electronics    150\n",
      "1          2    Water Bottle  10.00         Home    300\n",
      "First 2 rows of the table reviews\n",
      "   reviewid  productid  customerid  rating  \\\n",
      "0         1          1           1       4   \n",
      "1         2          4           2       5   \n",
      "\n",
      "                                      comment  reviewdate  \n",
      "0  Very responsive, but a bit noisy clicking.  2024-04-02  \n",
      "1    Excellent smartphone, fast and reliable.  2024-04-02  \n",
      "First 2 rows of the table shipments\n",
      "   shipmentid  orderid     status estimateddelivery\n",
      "0           1        1    Shipped        2024-04-03\n",
      "1           2        2  Delivered        2024-04-02\n"
     ]
    }
   ],
   "source": [
    "all_tables = wr.catalog.tables(database=database)\n",
    "tables = all_tables[\"Table\"].tolist()\n",
    "print(tables)\n",
    "\n",
    "for table in tables:\n",
    "    data = wr.athena.read_sql_query(f\"SELECT * FROM {table} LIMIT 10\", database=\"workshop_test\")\n",
    "    # print first 2 rows of the data\n",
    "    \n",
    "    print(f\"First 2 rows of the table {table}\")\n",
    "    print(data.head(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Generative AI using Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case. With Bedrock's serverless experience, you can get started quickly, privately customize FMs with your own data, and easily integrate and deploy them into your applications using the AWS tools without having to manage any infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Bedrock Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a boto3 bedrock client. We can use this client to issue API calls to Generative AI models available in Bedrock.\n",
    "\n",
    "Note: You can replace the profile_name with the profile name that is configured on your developer environment that has access to Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 Bedrock client successfully created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from botocore.config import Config\n",
    "import json\n",
    "retry_config = Config(\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "# region='us-west-2' # If you are using AWS provided account as part of an event use 'us-west-2'.\n",
    "region='us-east-1'\n",
    "session = boto3.Session(region_name=region, profile_name='default')\n",
    "bedrock_client = session.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        config=retry_config\n",
    "    )\n",
    "\n",
    "print(\"boto3 Bedrock client successfully created!\")\n",
    "\n",
    "############################\n",
    "# Note: You can also create a boto3 session with the credentials from environment variables\n",
    "############################\n",
    "\n",
    "# # Get the AWS credentials from environment variables\n",
    "# AWS_ACCESS_KEY_ID = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "# AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "# AWS_SESSION_TOKEN = os.environ.get('AWS_SESSION_TOKEN', None)  # Optional, if using temporary credentials\n",
    "\n",
    "# # Create a boto3 session with the credentials from environment variables\n",
    "# session = boto3.Session(\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "#     aws_session_token=AWS_SESSION_TOKEN,  # Include this line only if using temporary credentials\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Creating a function to call Bedrock API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a resuable function that uses the client we created above to call Claude 3 Sonnet model on Bedrock. We can pass prompt and temperature to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_bedrock_claude_3(prompt_text, temperature):\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_text\n",
    "                        }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    body = json.dumps(body)\n",
    "    response = bedrock_client.invoke_model(\n",
    "            body=body, modelId=model_id\n",
    "        )\n",
    "    # Parse the response\n",
    "    response_lines = response['body'].readlines()\n",
    "    json_str = response_lines[0].decode('utf-8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    result_text = json_obj['content'][0]['text']\n",
    "    \n",
    "    return result_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test a sample bedrock call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Using Claude 3 Sonnet model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "prompt = \"Hello...\"\n",
    "\n",
    "# Call Bedrock and get the response\n",
    "response = call_bedrock_claude_3(prompt, 0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Text to SQL with Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we'll showcase how to use generative AI models like Claude 3 to automatically generate SQL queries for analyzing data in Amazon S3 using Athena. We'll provide the AI model with the table schemas from the Glue Catalog and a natural language question describing the desired analysis. The model will then generate the corresponding Athena SQL query, which we can execute to retrieve the results. We'll also build an interactive chat widget that allows you to enter questions in plain English and see the AI-generated SQL queries and their output displayed interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Testing SQL generation and execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating a schemas dict which has list of all tables and corresponding columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all tables in the database workshop_test\n",
      "['customers', 'orderdetails', 'orders', 'payments', 'products', 'reviews', 'shipments']\n",
      "Schema for all tables in the database workshop_test\n",
      "{'customers': {'customer_id': 'bigint',\n",
      "               'email_id': 'string',\n",
      "               'first_name': 'string',\n",
      "               'last_name': 'string',\n",
      "               'phone_num': 'string'},\n",
      " 'orderdetails': {'orderdetailid': 'bigint',\n",
      "                  'orderid': 'bigint',\n",
      "                  'price': 'double',\n",
      "                  'productid': 'bigint',\n",
      "                  'quantity': 'bigint'},\n",
      " 'orders': {'customerid': 'bigint',\n",
      "            'orderdate': 'string',\n",
      "            'orderid': 'bigint',\n",
      "            'totalamount': 'double'},\n",
      " 'payments': {'amount': 'double',\n",
      "              'orderid': 'bigint',\n",
      "              'paymentdate': 'string',\n",
      "              'paymentid': 'bigint',\n",
      "              'paymenttype': 'string',\n",
      "              'status': 'string'},\n",
      " 'products': {'category': 'string',\n",
      "              'price': 'double',\n",
      "              'productid': 'bigint',\n",
      "              'productname': 'string',\n",
      "              'stock': 'bigint'},\n",
      " 'reviews': {'comment': 'string',\n",
      "             'customerid': 'bigint',\n",
      "             'productid': 'bigint',\n",
      "             'rating': 'bigint',\n",
      "             'reviewdate': 'string',\n",
      "             'reviewid': 'bigint'},\n",
      " 'shipments': {'estimateddelivery': 'string',\n",
      "               'orderid': 'bigint',\n",
      "               'shipmentid': 'bigint',\n",
      "               'status': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "database = \"workshop_test\"\n",
    "\n",
    "# List all tables in the database workshop_test\n",
    "all_tables = wr.catalog.tables(database=database)\n",
    "\n",
    "tables = all_tables[\"Table\"].tolist()\n",
    "\n",
    "print(\"List of all tables in the database workshop_test\")\n",
    "print(tables)\n",
    "\n",
    "\n",
    "# Get schema for all tables\n",
    "print(\"Schema for all tables in the database workshop_test\")\n",
    "\n",
    "all_schemas = {}\n",
    "for table in tables:\n",
    "    schema_str = wr.catalog.get_table_types(database=database, table=table)\n",
    "    all_schemas[table] = schema_str\n",
    "\n",
    "pprint.pprint(all_schemas)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"all_schemas.json\", \"w\") as outfile: \n",
    "    json.dump(all_schemas, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a simple prompt with placeholders for tables (schemas) and question. We will then format the prompt by inserting table schemas and question and invoke Claude model on Bedrock to generate SQL query. Finally, we will execute the SQL query using Athena.\n",
    "\n",
    "Note: We will use call_bedrock_claude_3 function created in the previous cells to invoke the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following list of tables, generate syntactically correct SQL query to answer the following question. \n",
      "\n",
      "\n",
      "Tables: \n",
      "\n",
      "{'customers': {'customer_id': 'bigint', 'first_name': 'string', 'last_name': 'string', 'email_id': 'string', 'phone_num': 'string'}, 'orderdetails': {'orderdetailid': 'bigint', 'orderid': 'bigint', 'productid': 'bigint', 'quantity': 'bigint', 'price': 'double'}, 'orders': {'orderid': 'bigint', 'customerid': 'bigint', 'orderdate': 'string', 'totalamount': 'double'}, 'payments': {'paymentid': 'bigint', 'orderid': 'bigint', 'paymenttype': 'string', 'amount': 'double', 'paymentdate': 'string', 'status': 'string'}, 'products': {'productid': 'bigint', 'productname': 'string', 'price': 'double', 'category': 'string', 'stock': 'bigint'}, 'reviews': {'reviewid': 'bigint', 'productid': 'bigint', 'customerid': 'bigint', 'rating': 'bigint', 'comment': 'string', 'reviewdate': 'string'}, 'shipments': {'shipmentid': 'bigint', 'orderid': 'bigint', 'status': 'string', 'estimateddelivery': 'string'}} \n",
      "\n",
      "\n",
      "\n",
      "Question: \n",
      "\n",
      "What is the total number of customers? \n",
      "\n",
      "\n",
      "\n",
      "Strict Instructions: \n",
      "\n",
      "- Always end with a semicolon. \n",
      "\n",
      "\n",
      "- Only include the SQL query in the response. \n",
      "\n",
      "\n",
      "- Always name all columns in the query. \n",
      "\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT COUNT(*) AS total_customers FROM customers;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_customers\n",
       "0               10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple SQL generation prompt\n",
    "prompt = \"\"\"Given the following list of tables, generate syntactically correct SQL query to answer the following question. \\n\\n\n",
    "Tables: \\n\n",
    "{tables} \\n\\n\n",
    "\n",
    "Question: \\n\n",
    "{question} \\n\\n\n",
    "\n",
    "Strict Instructions: \\n\n",
    "- Always end with a semicolon. \\n\\n\n",
    "- Only include the SQL query in the response. \\n\\n\n",
    "- Always name all columns in the query. \\n\\n\n",
    "SQL:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "question = \"What is the total number of customers?\"\n",
    "\n",
    "# Format the prompt\n",
    "prompt = prompt.format(tables=all_schemas, question=question)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "# Call Bedrock and get the response\n",
    "sql = call_bedrock_claude_3(prompt, 0.7)\n",
    "print(sql)\n",
    "\n",
    "# Run the generated SQL query\n",
    "df = wr.athena.read_sql_query(sql, database=database)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
